facet_wrap(~metric+condition)
View(semantic_similarities)
View(originality_trials)
View(both_ratings)
View(crowdworkers_submitters_ideas)
manual_ratings_model <- lmer(originality ~ condition + (1|trial) + (1|submitter_id), data=crowdworkers_submitters_ideas)
summary(m)
# # Create a mixed model and determine random effects from pilot data
manual_ratings_model <- lmer(originality ~ condition + (1|trial) + (1|submitter_id), data=crowdworkers_submitters_ideas)
summary(m)
#
# # trial variance
# rand <- .259
#
# # Residual SD
# s <- .341^.5
# # Create a mixed model and determine random effects from pilot data
manual_ratings_model <- lmer(creativity ~ condition + (1|trial) + (1|submitter_id), data=crowdworkers_submitters_ideas)
summary(m)
#
# # trial variance
# rand <- .259
#
# # Residual SD
# s <- .341^.5
# Create a mixed model and determine random effects from pilot data
manual_ratings_model <- lmer(creativity ~ condition + (1|trial) + (1|submitter_id), data=crowdworkers_submitters_ideas)
summary(m)
# Chunk 1
library(here) # to enable easy file referencing
library(renv) # helps create reproducible environments
library(tidyverse)
library(dplyr)
library(text)
library(descriptr)
library(ggsignif)
library(ggpubr)
library(scales)
library(lme4)
library(simr)
library(broom)
library(kableExtra)
library(knitr)
library(papaja) # For automatic formatting of statistics
# Chunk 2
# Remove question text rows
pilot_data <- read_csv("data/pilot_2025.09.11.csv") %>%
slice(-(1:2))
# Filter for participants who passed attention check
passed_attn_check <- pilot_data %>%
filter(attn_check == "4" & attn_check_4_TEXT == "8")
# Chunk 3
# Rename condition column
pilot_data_renamed <- passed_attn_check %>%
rename(condition = FL_3_DO) %>%
relocate(condition, .after = attn_check_4_TEXT) %>%
mutate(condition = case_when(condition == "GuidedInstructions" ~ "Pilot",
condition == "UnguidedInstructions" ~ "Passenger",
condition == "ControlInstructions" ~ "Control"))
# Filter for participants who correctly answered the memory check question about the condition to which they were assigned
# 1 = "Stay in control of the AI tool" (Pilot)
# 2 = "Let the AI tool do the heavy lifting (Passenger)
# 3 = "Don't use AI" (Control)
memory_check <- pilot_data_renamed %>%
mutate(memory_check_condition = case_when(memory_check == "1" ~ "Pilot",
memory_check == "2" ~ "Passenger",
is.na(memory_check) ~ "Control")) %>%
relocate(memory_check_condition, .after = "memory_check") %>%
mutate(memory_check_result = if_else(condition == memory_check_condition, 1, 0)) %>%
relocate(memory_check_result, .after = "memory_check_condition")
# Convert to long format
trial_data <- pilot_data_renamed %>%
pivot_longer(names_to = "trial",
values_to = "use",
cols = starts_with(c("pilot", "pass", "control"))) %>%
mutate(trial = str_remove(trial, "open_")) %>%
filter(!is.na(use)) %>%
relocate(trial, .after = "condition") %>%
relocate(use, .after = "trial") %>%
mutate(object = str_extract(trial, "(?<=_).*")) %>%
mutate(object = str_remove(object, "_.*")) %>%
relocate(object, .after = "trial") %>%
mutate(object = if_else(object == "bubble", "bubblewrap", object))
write_csv(trial_data, "data/trial_data.csv")
# Chunk 4
# Chunk 5
originality <- read_csv("data/trial_data_scored.csv")
# Add a column with trial number
originality_trials <- originality %>%
mutate(trial_num = str_extract(trial, "(?<=_)[^_]*$")) %>%
relocate(trial_num, .after = "trial")
# Originality by condition
ggplot(originality, aes(x=condition, y=originality)) +
geom_boxplot() +
stat_summary(fun="mean")
# Plot originality over the course of the study
originality_trials %>%
group_by(condition, trial_num) %>%
summarize(originality = mean(originality)) %>%
ggplot(aes(x=trial_num, y = originality, group=condition, color=condition)) +
geom_line() +
geom_point() +
labs(x="Trial Number") +
ylim(1,5)
# Chunk 6
options(digits=3)
# Group the uses by condition and object
trial_data %>%
select(ResponseId, condition, object, use) %>%
group_by(condition, object) %>%
arrange(condition, object)
# Use sentence transformers model in Python to analyze semantic similarity
semantic_similarities <- read_csv("data/semantic_similarities.csv")
semantic_similarities_summary <- read_csv("data/semantic_similarity_summary.csv")
semantic_similarities %>%
group_by(condition) %>%
summarize(mean_similarity = mean(similarity),
sd_similarity = sd(similarity)) %>%
arrange(desc(mean_similarity))
ggboxplot(semantic_similarities, x="condition", y="similarity", color="condition") +
stat_summary(fun="mean")
# Chunk 7
# Prepare idea submissions dataset for evaluation by another group of crowdworkers
# The data needs to be in long format, where each row represents a single idea for a single object
# In case you want to view wide
idea_submissions_wide <- trial_data %>%
mutate(trial = str_extract(trial, "([A-Za-z0-9]+)(_)([A-Za-z0-9]+)$")) %>%
pivot_wider(id_cols = c("ResponseId", "condition", "process_open-ended"),
names_from = "trial",
values_from = "use")
idea_submissions_long <- trial_data %>%
unite(col = "idea_id", ResponseId, trial, sep="-")
write_csv(idea_submissions_long, "data/idea_submissions.csv")
# Create separate csvs for frisbee, brick, and bubblewrap
frisbee_submissions <- idea_submissions_long %>%
filter(object=="frisbee")
brick_submissions <- idea_submissions_long %>%
filter(object=="brick")
bubble_submissions <- idea_submissions_long %>%
filter(object=="bubblewrap")
# Save to csvs
write_csv(frisbee_submissions, "data/frisbee_submissions.csv")
write_csv(brick_submissions, "data/brick_submissions.csv")
write_csv(bubble_submissions, "data/bubble_submissions.csv")
# Chunk 8
# Read in the crowdworker evaluations
# Each row represents a crowdworkers' responses. The data is super wide because each column represents a response to a single pilot study participant's idea
# First, wrangle the data so that the column format is similar to the pilot study data: frisbee_1, frisbee_2...bubble_5
crowdworkers <- read_csv("data/crowdworker_eval_2025.09.18.csv")
# Check which idea submitter is tied to which crowdworker
submitter_ids <- crowdworkers %>%
slice_head(n=1) %>%
pivot_longer(cols = 14:2038,
names_to = "participant_trial",
values_to = "submitter_id") %>%
select(participant_trial, submitter_id) %>%
mutate(submitter_id = str_extract(submitter_id, "R_[A-Za-z0-9]+")) %>%
separate(participant_trial,
into = c("person_id", "trial"),
extra = "merge") %>%
separate(col = trial,
into = c("metric", "trial"),
sep = "_",
extra = "merge") %>%
mutate(metric = case_when(metric == "c" ~ "creativity",
metric == "o" ~ "originality",
metric == "u" ~ "usefulness")) %>%
distinct(person_id, submitter_id)
crowdworker_eval <- crowdworkers %>%
filter(DistributionChannel=="anonymous")
crowdworker_passed_attn_check <- crowdworker_eval %>%
filter(attn_check == "4" & attn_check_4_TEXT == "8")
# Chunk 9
# Ensure there is a column for the ID of the pilot participant that the submitted idea came from
crowdworker_eval_long <- crowdworker_passed_attn_check %>%
pivot_longer(cols = 14:2038,
names_to = "participant_trial",
values_to = "rating") %>%
drop_na(rating) %>%
separate(col = participant_trial,
into = c("person_id", "trial"),
sep = "_",
extra = "merge") %>%
mutate(rating = as.numeric(rating)) %>%
separate(col = trial,
into = c("metric", "trial"),
sep = "_",
extra = "merge") %>%
mutate(metric = case_when(metric == "c" ~ "creativity",
metric == "o" ~ "originality",
metric == "u" ~ "usefulness")) %>%
unite(col="participant_rating_id", ResponseId, metric, trial, remove = FALSE) %>%
mutate(trial_id = str_remove(participant_rating_id, "_creativity|_originality|_usefulness")) %>%
pivot_wider(id_cols=c(trial_id, person_id),
names_from = "metric",
values_from = "rating")
crowdworkers_submitters <- left_join(crowdworker_eval_long, submitter_ids, by = "person_id") %>%
extract(trial_id,
into = c("crowdworker_id", "trial"),
regex = "(R_[A-Za-z0-9]+)_(.*)")
# Chunk 10
# Merge with trial data from the pilot
# participantID refers to the CloudResearch ID of the idea submitter
trial_data_renamed <- trial_data %>%
rename(submitter_id = "ResponseId") %>%
mutate(trial = str_remove(trial, "^[^_]*_")) %>%
select(submitter_id, condition, trial, object, use, participantId)
crowdworkers_submitters_ideas <- full_join(crowdworkers_submitters, trial_data_renamed, by=c("submitter_id", "trial"))
# Descriptives of overall creativity, originality, and usefulness by condition
crowdworkers_submitters_ideas %>%
group_by(condition) %>%
get_summary_stats(c(creativity, originality, usefulness),
type="mean_sd") %>%
arrange(variable)
# Chunk 11
bonuses <- crowdworkers_submitters_ideas %>%
group_by(participantId) %>%
get_summary_stats(c(creativity, originality, usefulness),
type="mean_sd") %>%
pivot_wider(id_cols = "participantId",
names_from = "variable",
values_from = "mean") %>%
filter(originality > 3 & usefulness > 3) %>%
select(-c(creativity, originality, usefulness)) %>%
rename("Participant or Assignment" = participantId) %>%
mutate(Amount = 1.00,
Message = "Great job! Your ideas scored high on creativity, so you receive a bonus.")
write_csv(bonuses, "data/pilot_bonus.csv")
# Chunk 12
crowdworkers_submitters_ideas %>%
pivot_longer(cols=c(creativity, originality, usefulness),
names_to = "metric",
values_to = "rating") %>%
ggplot(aes(x=condition, y=rating)) +
geom_boxplot() +
stat_summary(fun="mean") +
facet_wrap(~metric)
# Chunk 13
# Distributions of ratings for each condition
crowdworkers_submitters_ideas %>%
pivot_longer(cols=c(creativity, originality, usefulness),
names_to = "metric",
values_to = "rating") %>%
ggplot(aes(x=rating)) +
geom_histogram(bins=5,
color="white",
aes(y=after_stat(density))) +
facet_wrap(~metric+condition)
# Chunk 14
# For each pair of submitter_id and crowdworker_id we can compute mean ratings
crowdworkers_submitters_ideas %>%
group_by(submitter_id, crowdworker_id) %>%
summarize(mean_creativity = mean(creativity),
mean_originality = mean(originality),
mean_usefulness = mean(usefulness)) %>%
group_by(submitter_id) %>%
mutate(rater_num = row_number()) %>%
ungroup()
# What is the relationship between originality and overall creativity? Usefulness and overall creativity? Interaction between the two?
# Comparison of automated vs. manual originality evaluations
manual_ratings <- crowdworkers_submitters_ideas %>%
group_by(submitter_id) %>%
summarize(mean_creativity = mean(creativity),
mean_originality = mean(originality),
mean_usefulness = mean(usefulness)) %>%
rename(manual_originality = "mean_originality")
automated_ratings <- originality_trials %>%
group_by(ResponseId) %>%
summarize(originality = mean(originality)) %>%
rename(submitter_id = "ResponseId",
automated_originality = "originality")
cor.test(manual_ratings$manual_originality, automated_ratings$automated_originality)
both_ratings <- full_join(manual_ratings, automated_ratings, by="submitter_id")
ggplot(both_ratings, aes(x=manual_originality, y=automated_originality)) +
geom_point()
# Chunk 15
# originality_mod <- lm(originality ~ )
#
# kable(tidy(mod), digits=2)
#
# tstats <- t.test()
# Chunk 16
chat_log <- read_csv("data/cleaned_user_ai_conversations.csv")
# Chunk 17
# Create a mixed model and determine random effects from pilot data
manual_ratings_model <- lmer(creativity ~ condition + (1|trial) + (1|submitter_id), data=crowdworkers_submitters_ideas)
summary(m)
# Create a mixed model and determine random effects from pilot data
manual_ratings_model <- lmer(
creativity ~ condition + (1|trial) + (1|submitter_id), data=crowdworkers_submitters_ideas)
summary(manual_ratings_model)
# Create a mixed model and determine random effects from pilot data
manual_ratings_model <- lmer(
originality ~ condition + (1|trial) + (1|submitter_id), data=crowdworkers_submitters_ideas)
summary(manual_ratings_model)
# Create a mixed model from pilot data
manual_ratings_model <- lmer(
originality ~ condition + (1|trial) + (1|submitter_id), data=crowdworkers_submitters_ideas)
summary(manual_ratings_model)
# Decide how many submitters
unique_submitters <- crowdworkers_submitters_ideas$submitter_id
# Decide how many raters needed to evaluate those
unique_raters <- crowdworkers_submitters_ideas$crowdworker_id
# Decide how many submitters
unique_submitters <- unique(crowdworkers_submitters_ideas$submitter_id)
# Decide how many raters needed to evaluate those
unique_raters <- unique(crowdworkers_submitters_ideas$crowdworker_id)
# Put in a loop
sims <- 100
View(crowdworkers_submitters_ideas)
summary(manual_ratings_model)
sims <- 100
N <- 50
summaries <- list()
for (i in 1:sims) {
data_resamp <- crowdworkers_submitters_ideas %>%
slice_sample(n = N, replace = TRUE)
manual_ratings_model <- lmer(
originality ~ condition + (1|trial) + (1|submitter_id), data=crowdworkers_submitters_ideas)
summaries[[i]] <- summary(manual_ratings_model)
}
View(summaries)
summaries[[1]]
summaries[[1]]$coefficients
summaries[[1]]$coefficients[2:3, 3]
sims <- 100
N <- 50
summaries <- list()
for (i in 1:sims) {
data_resamp <- crowdworkers_submitters_ideas %>%
slice_sample(n = N, replace = TRUE)
manual_ratings_model <- lmer(
originality ~ condition + (1|trial) + (1|submitter_id), data=crowdworkers_submitters_ideas)
summaries[[i]] <- summary(manual_ratings_model)$coefficients[2:3, 3]
}
do.call(rbind, summaries)
sims <- 100
N <- 50
summaries <- list()
for (i in 1:sims) {
data_resamp <- crowdworkers_submitters_ideas %>%
slice_sample(n = N, replace = TRUE)
manual_ratings_model <- lmer(
originality ~ condition + (1|trial) + (1|submitter_id), data=data_resamp)
summaries[[i]] <- summary(manual_ratings_model)$coefficients[2:3, 3]
}
do.call(rbind, summaries)
sims <- 100
N <- 10000
summaries <- list()
for (i in 1:sims) {
data_resamp <- crowdworkers_submitters_ideas %>%
slice_sample(n = N, replace = TRUE)
manual_ratings_model <- lmer(
originality ~ condition + (1|trial) + (1|submitter_id), data=data_resamp)
summaries[[i]] <- summary(manual_ratings_model)$coefficients[2:3, 3]
}
do.call(rbind, summaries)
summaries_bound <- do.call(rbind, summaries)
# Create a mixed model from pilot data
manual_ratings_model <- lmer(
originality ~ condition + (1|trial) + (1|submitter_id), data=crowdworkers_submitters_ideas)
summary(manual_ratings_model)
# # Decide how many submitters
# unique_submitters <- unique(crowdworkers_submitters_ideas$submitter_id)
# unique_submitters_sample <- sample(unique_submitters, size = S, replace = TRUE)
#
# # Decide how many raters needed to evaluate those
# unique_raters <- unique(crowdworkers_submitters_ideas$crowdworker_id)
# unique_raters_sample <- sample(unique_raters, size = S, replace = TRUE)
# Loop through the sample of RATINGS
sims <- 100
N <- 10000
summaries <- list()
for (i in 1:sims) {
data_resamp <- crowdworkers_submitters_ideas %>%
slice_sample(n = N, replace = TRUE)
manual_ratings_model <- lmer(
originality ~ condition + (1|trial) + (1|submitter_id), data=data_resamp)
summaries[[i]] <- summary(manual_ratings_model)$coefficients[2:3, 3]
}
summaries_bound <- do.call(rbind, summaries)
# t must be greater than 2 to be significant. We just need absolute value
power_Passenger <- mean(abs(summaries_bound[,1]) > 2)
power_Pilot <- mean(abs(summaries_bound[,2]) > 2)
power_Passenger
power_Pilot
# Create a mixed model from pilot data
manual_ratings_model <- lmer(
originality ~ condition + (1|trial) + (1|submitter_id), data=crowdworkers_submitters_ideas)
summary(manual_ratings_model)
# # Decide how many submitters
# unique_submitters <- unique(crowdworkers_submitters_ideas$submitter_id)
# unique_submitters_sample <- sample(unique_submitters, size = S, replace = TRUE)
#
# # Decide how many raters needed to evaluate those
# unique_raters <- unique(crowdworkers_submitters_ideas$crowdworker_id)
# unique_raters_sample <- sample(unique_raters, size = S, replace = TRUE)
# Loop through the sample of RATINGS
sims <- 1000
N <- 50000
summaries <- list()
for (i in 1:sims) {
data_resamp <- crowdworkers_submitters_ideas %>%
slice_sample(n = N, replace = TRUE)
manual_ratings_model <- lmer(
originality ~ condition + (1|trial) + (1|submitter_id), data=data_resamp)
summaries[[i]] <- summary(manual_ratings_model)$coefficients[2:3, 3]
}
summaries_bound <- do.call(rbind, summaries)
# t must be greater than 2 to be significant. We just need absolute value
power_Passenger <- mean(abs(summaries_bound[,1]) > 2)
power_Pilot <- mean(abs(summaries_bound[,2]) > 2)
power_Passenger
power_Pilot
View(summaries)
sims <- 1000
N <- 1485000
summaries <- list()
for (i in 1:sims) {
data_resamp <- crowdworkers_submitters_ideas %>%
slice_sample(n = N, replace = TRUE)
manual_ratings_model <- lmer(
originality ~ condition + (1|trial) + (1|submitter_id), data=data_resamp)
summaries[[i]] <- summary(manual_ratings_model)$coefficients[2:3, 3]
}
install.packages("progress")
library(progress)
sims <- 1000
S <- 1000 # This can be adjusted to test different numbers of submitters
summaries <- list()
for (i in 1:sims) {
# data_resamp <- crowdworkers_submitters_ideas %>%
# slice_sample(n = N, replace = TRUE)
unique_submitters_sample <- sample(unique_submitters, size = S, replace = TRUE)
data_sample_list <- list()
for (j in 1:length(unique_submitters_sample)){
data_sample_list[[j]] <- crowdworkers_submitters_ideas %>%
filter(submitter_id == unique_submitters_sample[j]) %>%
mutate(submitter_id = paste0(submitter_id, j))
}
data_resamp <- do.call(rbind, data_sample_list)
manual_ratings_model <- lmer(
originality ~ condition + (1|trial) + (1|submitter_id), data=data_resamp)
summaries[[i]] <- summary(manual_ratings_model)$coefficients[2:3, 3]
}
summaries_bound <- do.call(rbind, summaries)
# t must be greater than 2 to be significant. We just need absolute value
power_Passenger <- mean(abs(summaries_bound[,1]) > 2)
power_Pilot <- mean(abs(summaries_bound[,2]) > 2)
power_Passenger
power_Pilot
warnings()
sims <- 1000
S <- 500 # This can be adjusted to test different numbers of submitters
summaries <- list()
for (i in 1:sims) {
# data_resamp <- crowdworkers_submitters_ideas %>%
# slice_sample(n = N, replace = TRUE)
unique_submitters_sample <- sample(unique_submitters, size = S, replace = TRUE)
data_sample_list <- list()
for (j in 1:length(unique_submitters_sample)){
data_sample_list[[j]] <- crowdworkers_submitters_ideas %>%
filter(submitter_id == unique_submitters_sample[j]) %>%
mutate(submitter_id = paste0(submitter_id, j))
}
data_resamp <- do.call(rbind, data_sample_list)
manual_ratings_model <- lmer(
originality ~ condition + (1|trial) + (1|submitter_id), data=data_resamp)
summaries[[i]] <- summary(manual_ratings_model)$coefficients[2:3, 3]
}
summaries_bound <- do.call(rbind, summaries)
# t must be greater than 2 to be significant. We just need absolute value
power_Passenger <- mean(abs(summaries_bound[,1]) > 2)
power_Pilot <- mean(abs(summaries_bound[,2]) > 2)
power_Passenger
power_Pilot
summaries_bound <- do.call(rbind, summaries)
# t must be greater than 2 to be significant. We just need absolute value
power_Passenger <- mean(abs(summaries_bound[,1]) > 2)
power_Pilot <- mean(abs(summaries_bound[,2]) > 2)
power_Passenger
power_Pilot
summaries_bound <- do.call(rbind, summaries)
power_Passenger <- mean(abs(summaries_bound[,1]) > 2)
power_Pilot <- mean(abs(summaries_bound[,2]) > 2)
power_Passenger
power_Pilot
sims <- 1000
S <- 300 # This can be adjusted to test different numbers of submitters
summaries <- list()
for (i in 1:sims) {
# data_resamp <- crowdworkers_submitters_ideas %>%
# slice_sample(n = N, replace = TRUE)
unique_submitters_sample <- sample(unique_submitters, size = S, replace = TRUE)
data_sample_list <- list()
for (j in 1:length(unique_submitters_sample)){
data_sample_list[[j]] <- crowdworkers_submitters_ideas %>%
filter(submitter_id == unique_submitters_sample[j]) %>%
mutate(submitter_id = paste0(submitter_id, j))
}
data_resamp <- do.call(rbind, data_sample_list)
manual_ratings_model <- lmer(
originality ~ condition + (1|trial) + (1|submitter_id), data=data_resamp)
summaries[[i]] <- summary(manual_ratings_model)$coefficients[2:3, 3]
}
summaries_bound <- do.call(rbind, summaries)
# t must be greater than 2 to be significant. We just need absolute value
power_Passenger <- mean(abs(summaries_bound[,1]) > 2)
power_Pilot <- mean(abs(summaries_bound[,2]) > 2)
power_Passenger
power_Pilot
