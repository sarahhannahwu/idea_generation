---
title: "Creativity with AI (IRiSS sample)"
format: 
  html:
    toc: true
    toc-depth: 3
    code-overflow: wrap
    code-fold: true
    df-print: paged
    css: |
      body {
        max-width: 1200px;
        word-wrap: break-word;
      }
      pre code {
        white-space: pre-wrap;
      }
editor: visual
---

# IRiSS

## Libraries

```{r global_options, include=FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE, echo = TRUE)

library(here) # to enable easy file referencing
library(renv) # helps create reproducible environments
library(tidyverse)
library(dplyr)
library(text)
library(ggtext)
library(descriptr)
library(ggsignif)
library(ggpubr)
library(scales)
library(lme4)
library(lmerTest)
library(simr)
library(broom)
library(kableExtra)
library(knitr)
library(papaja) # For automatic formatting of statistics
library(progress)
library(emmeans)
library(ggrepel)
library(RColorBrewer)
library(ggridges)
library(sjPlot)
library(webshot)
library(effectsize)
library(lavaan)
library(patchwork)
library(gtsummary)
library(sjstats)
library(ltm)
library(wCorr)
library(rstatix)
library(pwr)
library(lavaan)
library(mediation)
library(QuantPsyc)
library(gt)
library(multcomp)
library(ggdist)
library(viridis)
library(stargazer)
library(factoextra)
library(cluster)

```

## IRiSS Sample

Note: The analyses on poster start at 'H1 and H2: Compliant Analyses.'

```{r}
iriss <- read_csv("data/iriss.csv") %>% 
  slice(-(1:2)) %>% 
  filter(attn_check == "4" & attn_check_4_TEXT == "8") %>% 
  rename(condition = FL_3_DO) %>% 
  relocate(condition, .after = attn_check_4_TEXT) %>% 
  mutate(condition = case_when(condition == "GuidedInstructions" ~ "high-agency",
                               condition == "UnguidedInstructions" ~ "low-agency",
                               condition == "ControlInstructions" ~ "Control")) %>% 
  filter(Progress=="100") %>% 
  rename(submitter_id = "ResponseId") %>% 
  mutate(age = as.numeric(age))

iriss %>% 
  get_summary_stats(age, type="mean_sd")


```

```{r}
submitter_demographics <- iriss %>%
  mutate(gender = case_when(gender == "1" ~ "Male",
                            gender == "2" ~ "Female",
                            gender == "3" ~ "Non-binary",
                            gender == "4" ~ "Prefer to self-describe")) %>% 
  mutate(race = case_when(race == "1" ~ "Black or African-American",
                          race == "2" ~ "American Indian or Alaskan Native",
                          race == "3" ~ "White or Caucasian",
                          race == "4" ~ "Native Hawaiian",
                          race == "5" ~ "Hispanic, Latino or Spanish Origin",
                          race == "6" ~ "Asian-American",
                          race == "7" ~ "Multiracial or self-described")) %>% 
  mutate(race = fct_infreq(race)) %>% 
  dplyr::select(submitter_id, age, gender, race) 

submitter_demographics %>% 
  tbl_summary(include = c(age, gender, race),
              statistic = list(
                all_continuous() ~ "{mean} ({sd})",
                all_categorical() ~ "{n} / {N} ({p}%)"),
              digits = all_continuous() ~ 1,
              label = list(age = "Age",
                           gender = "Gender",
                           race = "Race")) %>% 
   modify_header(label ~ "**Demographic**")


```

```{r}

iriss_memory_check <- iriss %>% 
  mutate(memory_check_condition = case_when(memory_check == "1" ~ "high-agency",
                                            memory_check == "2" ~ "low-agency",
                                            is.na(memory_check) ~ "Control")) %>% 
  relocate(memory_check_condition, .after = "memory_check") %>% 
  mutate(memory_check_result = if_else(condition == memory_check_condition, 1, 0)) %>% 
  relocate(memory_check_result, .after = "memory_check_condition")

# Check the % of participants who remembered what the instructions said
iriss_memory_check %>% 
  count(memory_check_result) %>% 
  mutate(prop=n/sum(n))

iriss_memory_check %>% 
  count(condition)


```

```{r}
# Convert to long format
iriss_trial_data <- iriss %>% 
  pivot_longer(names_to = "trial",
                values_to = "use",
                cols = starts_with(c("pilot", "pass", "control"))) %>% 
  mutate(trial = str_remove(trial, "open_")) %>% # fixed naming problem
  filter(grepl("^(pilot|pass|control)_(brick|frisbee|bubble)_[1-5]$", trial)) %>% 
  filter(!is.na(use)) %>% # Keep only the trials with responses
  relocate(trial, .after = "condition") %>% 
  relocate(use, .after = "trial") %>% 
  mutate(object = str_extract(trial, "(?<=_).*")) %>% 
  mutate(object = str_remove(object, "_.*")) %>% 
  relocate(object, .after = "trial") %>% 
  mutate(object = if_else(object == "bubble", "bubblewrap", object))

write_csv(iriss_trial_data, "data/iriss_trial_data.csv")
```

```{r}
iriss_self_perceptions <- iriss %>% 
  pivot_longer(names_to = "metric",
               values_to = "rating",
               cols = c(ends_with("_unique"),
                        matches("self_[1-3]$"))) %>% 
  drop_na(rating) %>% 
  mutate(metric = str_replace_all(metric, 
                                  c("self_1" = "creativity",
                                    "self_2" = "originality",
                                    "self_3" = "usefulness"))) %>% 
  separate(
    col = metric,
    into = c("condition", "object", "question"),
    sep = "_",
    remove = TRUE# keep original column if you still want it
  ) %>% 
  mutate(
    object = str_replace_all(
      object,
      c("\\bfris\\b" = "frisbee",
        "\\bbubb\\b"  = "bubble"))) %>% 
  mutate(condition = case_when(condition == "pilot" ~ "High-Agency",
                               condition == "pass" ~ "Low-Agency",
                               condition == "control" ~ "Control")) %>% 
  pivot_wider(names_from = "question",
              values_from = "rating") %>% 
  mutate(across(c(creativity, originality, usefulness), as.numeric))

```

```{r}
# Self-perceptions of creativity, originality, usefulness

self_perception_outcomes <- c("originality", "creativity", "usefulness")

self_perception_plots <- map(self_perception_outcomes, function(var) {
  summary_df <- iriss_self_perceptions %>%
    mutate(condition = fct_relevel(as.factor(condition), c("Low-Agency", "High-Agency", "Control"))) %>% 
    group_by(submitter_id, condition) %>%
    summarize(value = mean(.data[[var]]), .groups = "drop")
  
  ggplot(summary_df, aes(x = value, y = condition, fill = condition)) +
    geom_density_ridges(alpha = 0.6, quantile_lines = TRUE, quantile_fun = mean) +
    xlim(c(1,5)) +
    labs(x = paste0("Self-perceived ", var), y = "") +
    theme_apa() +
    theme(legend.position = "none")
})

# To display the plots:
self_originality <- self_perception_plots[[1]]  # originality
self_creativity<- self_perception_plots[[2]]  # creativity
self_usefulness <- self_perception_plots[[3]]  # usefulness

self_creativity
self_originality
self_usefulness

# Combined plot
combined_self_plot <- self_creativity + self_originality + self_usefulness + plot_annotation(tag_levels = "a")
combined_self_plot

ggsave(plot=combined_self_plot, filename="figures/self_perceptions.png")
# Mixed model


```

```{r}
# Relationship between self-perception and third-party perception
iriss_self_perceptions %>% 
  rename(self_creativity = creativity,
         self_originality = originality,
         self_usefulness = usefulness) 

# Correlation?
```

```{r}
# How unique did participants think their ideas were?
perceived_uniqueness <- iriss_self_perceptions %>% 
  drop_na(unique) %>% 
  group_by(condition) %>% 
  count(unique) %>% 
  mutate(prop=n/sum(n)) %>% 
  ggplot(aes(x=unique, y=prop, fill=condition)) +
  geom_col(position = "dodge") +
  scale_x_discrete(labels = c(
    "1" = "No one",
    "2" = "Some people",
    "3" = "Most people",
    "4" = "Everyone"
  )) +
  labs(x="How many people came up with this idea?",
       y="Proportion of responses") +
  theme_apa()

ggsave("figures/uniqueness.png", plot=perceived_uniqueness)
```

```{r}
# How does mean originality compare across conditions?

iriss_self_perceptions %>% 
  drop_na(originality) %>% 
  group_by(submitter_id, condition) %>% 
  summarize(originality = mean(originality)) %>% 
  ggplot(aes(x=condition, y=originality)) +
  geom_boxplot() +
  stat_summary(fun="mean") +
  labs(y="Self-perceived originality")
```

### Self perceptions

```{r}
# Make sure the reference group is the Control group!
iriss_self_originality_mod <- lmer(
  originality ~ condition + (1|object) + (1|submitter_id), data= iriss_self_perceptions)
summary(iriss_self_originality_mod)

iriss_self_creativity_mod <- lmer(
  creativity ~ condition + (1|object) + (1|submitter_id), data= iriss_self_perceptions)
summary(iriss_self_creativity_mod)

iriss_self_usefulness_mod <- lmer(
  usefulness ~ condition + (1|object) + (1|submitter_id), data= iriss_self_perceptions)
summary(iriss_self_usefulness_mod)
```

Participants in the high-agency condition perceived their ideas as more useful than the other participants.

```{python, echo=FALSE}
# from sentence_transformers import SentenceTransformer
# import pandas as pd
# import numpy as np
# import os
# # os.environ["TOKENIZERS_PARALLELISM"] = "false"
# 
# 
# # Load the sentence transformer model
# model = SentenceTransformer('all-MiniLM-L6-v2')
# 
# # Load the data
# 
# data_path = '~/Git_Projects/idea_generation/data/iriss_trial_data.csv'  # Update with your actual data path
# df = pd.read_csv(data_path)
# 
# # For each combination of experimental condition, object, and submitter_id, compute the semantic similarity of ideas
# results = []
# for (condition, obj, response_id), group in df.groupby(['condition', 'object', 'submitter_id']):
#     ideas = group['use'].tolist()
# 
#     # Compute embeddings
#     embeddings = model.encode(ideas)
# 
#     # Compute cosine similarity matrix
#     norm_embeddings = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)
#     similarity_matrix = np.dot(norm_embeddings, norm_embeddings.T)
# 
#     # Extract upper triangle of the similarity matrix, excluding the diagonal
#     upper_tri_indices = np.triu_indices_from(similarity_matrix, k=1)
#     similarities = similarity_matrix[upper_tri_indices]
# 
#     # Store results
#     for sim in similarities:
#         results.append({
#             'condition': condition,
#             'object': obj,
#             'submitter_id': submitter_id,
#             'similarity': sim
#         })
# 
# # Convert results to DataFrame
# results_df = pd.DataFrame(results)
# summary = results_df.groupby('condition')['similarity'].agg(['mean', 'std'])
# print(summary)
# 
# # Save results to CSV
# output_path = os.path.expanduser('~/Git_Projects/idea_generation/data/iriss_semantic_similarities.csv')  # Update with your desired output path
# results_df.to_csv(output_path, index=False)
```

```{r}
# iriss_semantic_similarities %>% 
#   group_by(condition, submitter_id) %>% 
#   summarize(similarity = mean(similarity)) %>% 
#   ggplot(aes(x=condition, y=similarity)) +
#   geom_boxplot() +
#   stat_summary(fun="mean") 
```

```{r}
# emmeans(iriss_semantic_similarity_mod, pairwise ~ condition, adjust="bonferroni")
```

## Crowdsourced originality ratings

```{r}
iriss_manual_ratings <- read_csv("data/iriss_manual_ratings.csv") %>% 
  filter(DistributionChannel=="anonymous") %>% 
  filter(attn_check == "4" & attn_check_4_TEXT == "8") %>% 
  drop_na(frisbee.0.condition)  %>%  # Drop rows with missing data (experimenter error) 
  mutate(age = as.numeric(age))


```

```{r}
# evaluator_demographics <- iriss_manual_ratings %>% 
#   mutate(age = if_else(age < 18 | age > 100, NA_real_, age)) %>% 
#   mutate(gender = case_when(gender == "1" ~ "Male",
#                             gender == "2" ~ "Female",
#                             gender == "3" ~ "Non-binary",
#                             gender == "4" ~ "Prefer to self-describe")) %>% 
#   mutate(race = case_when(race == "1" ~ "Black or African-American",
#                           race == "2" ~ "American Indian or Alaskan Native",
#                           race == "3" ~ "White or Caucasian",
#                           race == "4" ~ "Native Hawaiian",
#                           race == "5" ~ "Hispanic, Latino or Spanish Origin",
#                           race == "6" ~ "Asian-American",
#                           race == "7" ~ "Multiracial or self-described")) %>% 
#   mutate(race = fct_infreq(race)) %>% 
#   select(age, gender, race) %>% 
#   tbl_summary(include = c(age, gender, race),
#               statistic = list(
#                 all_continuous() ~ "{mean} ({sd})",
#                 all_categorical() ~ "{n} / {N} ({p}%)"),
#               digits = all_continuous() ~ 1,
#               label = list(age = "Age",
#                            gender = "Gender",
#                            race = "Race")) %>% 
#    modify_header(label ~ "**Demographic**")
# evaluator_demographics
# 
# combined_demographics <- tbl_merge(
#   tbls = list(submitter_demographics, evaluator_demographics),
#   tab_spanner = c("**Submitters**", "**Evaluators**")
# )
# 
# combined_demographics
```

```{r}
iriss_manual_ratings_long <- iriss_manual_ratings %>% 
  rename(rater_id = ResponseId) %>% 
  pivot_longer(cols = frisbee.0.condition:bubblewrap.4.use,
               names_to = "stimulus_metadata",
               values_to = "value") %>% 
  mutate(metadata = str_extract(stimulus_metadata, "[^.]+$"),
         stimulus_metadata = str_remove(stimulus_metadata, "\\.[^.]+$")) %>% 
  separate_wider_delim(stimulus_metadata,
           ".",
           names = c("object", "trial_num")) %>% 
  pivot_wider(
              names_from = "metadata",
              values_from = "value") %>% 
  rename(submitter_id = ResponseId)

# Pivot to give each creativity rating its own column
iriss_manual_ratings_metrics <- iriss_manual_ratings_long %>% 
  pivot_longer(cols = c_frisbee_1:u_bubble_5,
               names_to = "trial",
               values_to = "rating") %>% 
  mutate(rating = as.numeric(rating)) %>% 
  mutate(metric = str_extract(trial, "^[A-Za-z]+(?=_)")) %>% 
  mutate(metric = case_when(metric == "c" ~ "creativity",
                            metric == "o" ~ "originality",
                            metric == "u" ~ "usefulness")) %>% 
  dplyr::select(rater_id, object, trial_num, submitter_id, condition, use, trial, metric, rating) %>% 
  mutate(trial = str_remove(trial, "^._")) %>% 
  mutate(trial_num = as.numeric(trial_num),
         trial_num = trial_num+1) %>% 
  unite(col="stimulus", c("object", "trial_num")) %>% 
  mutate(trial = str_replace_all(trial, "bubble", "bubblewrap")) %>% # Check names!
  filter(stimulus==trial) %>% 
  pivot_wider(names_from = "metric",
              values_from = "rating") %>% 
  mutate(object = str_extract(stimulus, "^[A-Za-z]+")) %>% 
  relocate(object, .after = "stimulus") %>% 
  mutate(use_word_count = str_count(use, "\\S+")) %>% 
  relocate(use_word_count, .after = use) %>% 
  mutate(condition=case_when(condition=="Pilot"~"High-Agency",
                             condition=="Passenger"~"Low-Agency",
                             condition=="Control"~"Control"))

# Select process variables from full dataset
process_vars <- iriss_trial_data %>% 
  dplyr::select(submitter_id, object, starts_with("conv_with_ai"), starts_with("consideration_aid"), starts_with("intrinsic_motivation")) %>% 
  distinct()



write_csv(iriss_manual_ratings_metrics, "data/iriss_manual_ratings_metrics.csv")
```

### Descriptives

```{r}
iriss_manual_ratings_metrics %>% 
  group_by(condition) %>% 
  get_summary_stats(use_word_count, type="mean_sd")

iriss_manual_ratings_metrics %>% 
  ggplot(aes(x=condition, y=use_word_count)) +
  geom_boxplot() +
  stat_summary(fun="mean")

cor.test(iriss_manual_ratings_metrics$use_word_count, iriss_manual_ratings_metrics$originality)

ggplot(iriss_manual_ratings_metrics, aes(x=use_word_count, y=originality, color=condition)) +
  geom_jitter() +
  geom_smooth(method="lm")


```

Higher word count is associated with greater originality.

### Originality analysis

```{r}
iriss_manual_ratings_metrics %>% 
  group_by(condition) %>%
  get_summary_stats(c(creativity, originality, usefulness), type="mean_sd") %>% 
  arrange(variable)

iriss_manual_ratings_metrics %>% 
  group_by(condition) %>% 
  count(originality) %>% 
  mutate(prop=n/sum(n)) %>% 
  ggplot(aes(x=originality, y=prop)) +
  geom_col(color="white") +
  facet_wrap(~condition)

# Descriptives table
summary_table <- iriss_manual_ratings_metrics %>%
  mutate(condition=fct_relevel(as.factor(condition), "low-agency", "high-agency", "Control")) %>% 
  group_by(condition) %>%
  get_summary_stats(c(creativity, originality, usefulness), type = "mean_sd") %>%
  mutate(mean_sd = sprintf("%.2f (%.2f)", mean, sd)) %>%
  select(condition, variable, mean_sd) %>%
  pivot_wider(names_from = variable, values_from = mean_sd)

summary_table %>%
  kbl(
    col.names = c("Condition", "Creativity", "Originality", "Usefulness"),
    align = "lccc",
    booktabs = TRUE
  ) %>%
  kable_styling(
    html_font = "helvetica",
    full_width = FALSE,
    position = "center",
  ) 
```

### Heatmap of creativity "sweet spots"

```{r, echo=FALSE}
label_points <- iriss_manual_ratings_metrics %>% 
  group_by(condition) %>% 
  sample_n(10)

# Might want to change the colors 
iriss_manual_ratings_metrics %>% 
  group_by(originality, usefulness) %>% 
  summarize(creativity=mean(creativity)) %>% 
  ggplot(aes(x=originality, y=usefulness, fill=creativity)) +
  geom_tile(color="black") +
  geom_label_repel(
    data=label_points,
    aes(label = str_wrap(paste(object, use, sep = ": "), width = 20)),
    size=2.5,
    color="black",
    alpha=.75) +
  facet_wrap(~condition) +
  scale_fill_gradient(low = "darkgrey", 
                      high = "gold",
                      breaks  = range(iriss_manual_ratings_metrics$creativity, na.rm = TRUE), 
                      labels = c("Not at all", "Maximally")) +
  labs(fill="Evaluators'\n creativity rating",
       x="Originality",
       y="Usefulness") +
  theme_apa() +
  theme(
    legend.position = "bottom",
    legend.title = element_text(vjust = 1, hjust = 0.5),
    legend.text.align = 0.5
  ) +
  guides(
    fill = guide_colorbar(
      title.position = "top",    # put title above bar
      title.hjust = 0.5,         # center title
      label.hjust = 0.5,         # center tick labels
      barwidth = unit(6, "cm"),  # adjust width as needed
      barheight = unit(0.4, "cm") 
    )
  )



```

How much did people index on each dimension of creativity?

```{r}
rating_dimensions_mod <- lmer(creativity ~ originality + usefulness + (originality + usefulness | rater_id), data = iriss_manual_ratings_metrics)

summary(rating_dimensions_mod)
```

People tended to weight originality more than usefulness.

```{r}
iriss_manual_ratings_metrics %>% 
  group_by(submitter_id, condition) %>% 
  summarize(originality=mean(originality)) %>%
  ggplot(aes(x=originality, y=condition)) +
  geom_density_ridges()
```

### Plots for H1

```{r}
outcomes <- c("originality", "creativity", "usefulness")

plots <- map(outcomes, function(var) {
  summary_df <- iriss_manual_ratings_metrics %>%
    group_by(submitter_id, condition) %>%
    summarize(value = mean(.data[[var]]), .groups = "drop")
  
  ggplot(summary_df, aes(x = value, y = condition, fill = condition)) +
    geom_density_ridges(alpha=.6, quantile_lines = TRUE, quantile_fun = mean) +
    xlim(c(1,5)) +
    labs(x = var, y = "") +
    theme_apa() +
    theme(legend.position = "none")
})

# To display the plots:
originality <- plots[[1]]  # originality
creativity <- plots[[2]]  # creativity
usefulness <- plots[[3]]  # usefulness

ggsave("figures/originality.png", plot = plots[[1]])
ggsave("figures/creativity.png", plot = plots[[2]])
ggsave("figures/usefulness.png", plot = plots[[3]])


# Combined plot
combined_evaluation_plot <- creativity + originality + usefulness + plot_annotation(tag_levels = "a")
combined_evaluation_plot

ggsave(plot=combined_evaluation_plot, filename="figures/evaluations.png")
```

```{r, echo=FALSE}
# semantic_similarity <- ggplot(iriss_semantic_similarities, aes(x=similarity, y=condition, fill=condition)) +
#   geom_density_ridges(alpha=.6,
#                       quantile_lines = TRUE,
#                       quantile_fun = mean) +
#   scale_x_continuous(breaks=seq(-.5, 1, by=.1)) +
#   labs(x="cosine similarity") +
#   theme_apa() +
#   theme(legend.position = "none") 
# 
# ggsave("figures/semantic_similarity.png", plot=semantic_similarity)
```

## H1: Individual-level creativity, originality, and usefulness

```{r}
iriss_originality_mod <- lmer(
  originality ~ condition + (1|object) + (1|submitter_id), data= iriss_manual_ratings_metrics)
summary(iriss_originality_mod)
anova(iriss_originality_mod)

coef(summary(iriss_originality_mod))

# anova(iriss_originality_mod)
# F_to_eta2(4.45, df=2, df_error=120)
# eta_squared(compliant_semantic_similarity_mod)


emmeans(iriss_originality_mod, pairwise ~ condition, adjust = "bonferroni")

# With demographic covariates
demographics <- iriss %>% 
  mutate(gender = case_when(gender == "1" ~ "Male",
                            gender == "2" ~ "Female",
                            gender == "3" ~ "Non-binary",
                            gender == "4" ~ "Prefer to self-describe")) %>% 
  mutate(race_recoded = if_else(race == "3", "White", "Non-White")) %>%
  select(submitter_id, age, race_recoded, gender, education)

iriss_manual_ratings_demographics <- left_join(iriss_manual_ratings_metrics, demographics, by="submitter_id")

#Adjust
iriss_originality_demographics <- lmer(
  originality ~ condition + scale(age) + as.factor(gender) + as.factor(race_recoded) + as.factor(education) + (1|object) + (1|submitter_id), data= iriss_manual_ratings_demographics)
summary(iriss_originality_demographics)
coef(summary(iriss_originality_demographics))


# Repeat models for creativity and usefulness
iriss_creativity_mod <- lmer(
  creativity ~ condition + (1|object) + (1|submitter_id), data= iriss_manual_ratings_metrics)
summary(iriss_creativity_mod)

iriss_usefulness_mod <- lmer(
  usefulness ~ condition + (1|object) + (1|submitter_id), data= iriss_manual_ratings_metrics)
summary(iriss_usefulness_mod)
```

Which conditions contributed the most creative ideas?

```{r}
iriss_manual_ratings_metrics %>%
  group_by(condition) %>%
  summarize(
    proportion = mean(originality > 3 & usefulness > 3)
  )

# Define thresholds as functions
thresholds <- list(
  ">3" = function(x) x > 3,
  ">4" = function(x) x > 4,
  "=5" = function(x) x == 5
)

# Compute proportions for every condition Ã— threshold
prop_by_threshold <- map_df(names(thresholds), function(thresh_name) {
  
  fn <- thresholds[[thresh_name]]
  
  iriss_manual_ratings_metrics %>%
    mutate(meets = fn(originality)) %>%
    group_by(condition) %>%
    summarise(
      n = n(),
      count = sum(meets),
      prop = count / n,
      se = sqrt(prop * (1 - prop) / n),
      lower = pmax(0, prop - 1.96 * se),
      upper = pmin(1, prop + 1.96 * se),
      .groups = "drop"
    ) %>%
    mutate(threshold = thresh_name)
})

# Reorder factor levels for plotting
prop_by_threshold$threshold <- factor(prop_by_threshold$threshold, levels = c(">3", ">4", "=5"))

ggplot(prop_by_threshold, aes(x = threshold, y = prop, color = condition, group = condition)) +
  geom_linerange(aes(ymin = lower, ymax = upper), position = position_dodge(width = 0.4), linewidth = 0.8) +
  geom_point(size = 4, position = position_dodge(width = 0.4)) +
  geom_line(position = position_dodge(width = 0.4), linewidth = 1) +   # connects points for each condition
  ylim(0, 1) +
  scale_color_manual(values = c("Control" = "#619bff", "High-Agency" = "#00BA38", "Low-Agency" = "#F8766D")) +
  labs(
    x = "Originality threshold",
    y = "Proportion of ideas meeting threshold",
    color = "Condition"
  ) +
  theme_minimal(base_size = 14)

# Compute proportions for usefulness
prop_by_threshold_use <- map_df(names(thresholds), function(thresh_name) {
  fn <- thresholds[[thresh_name]]
  iriss_manual_ratings_metrics %>%
    mutate(meets = fn(usefulness)) %>%
    group_by(condition) %>%
    summarise(
      n = n(),
      count = sum(meets),
      prop = count / n,
      se = sqrt(prop * (1 - prop) / n),
      lower = pmax(0, prop - 1.96 * se),
      upper = pmin(1, prop + 1.96 * se),
      .groups = "drop"
    ) %>%
    mutate(threshold = thresh_name)
})

prop_by_threshold_use$threshold <- factor(prop_by_threshold_use$threshold, levels = c(">3", ">4", "=5"))

# Plot
ggplot(prop_by_threshold_use, aes(x = threshold, y = prop, color = condition, group = condition)) +
  geom_linerange(aes(ymin = lower, ymax = upper), position = position_dodge(width = 0.4), linewidth = 0.8) +
  geom_point(size = 4, position = position_dodge(width = 0.4)) +
  ylim(0, 1) +
  scale_color_manual(values = c("Control" = "#619bff", "High-Agency" = "#00BA38", "Low-Agency" = "#F8766D")) +
  labs(
    x = "Usefulness threshold",
    y = "Proportion of ideas meeting threshold",
    color = "Condition"
  ) +
  theme_minimal(base_size = 14)



```

```{r}

```

low-agency participants produced the most creative ideas, followed by high-agency participants, then participants in the control condition.

What were the highest-performing ideas?

```{r}
iriss_manual_ratings_metrics %>% 
  arrange(desc(creativity)) %>% 
  dplyr::select(object, submitter_id, condition, use, creativity, originality, usefulness) %>% 
  print(n=100)
```

### Most common uses for each object

```{r}
iriss_manual_ratings_metrics %>% 
  mutate(use = str_to_lower(use)) %>% 
  group_by(object) %>% 
  count(use) %>% 
  arrange(desc(n)) %>% 
  print(n=30)

compliant_ideas %>% 
  filter(condition=="Low-Agency") %>% 
  mutate(use = str_to_lower(use)) %>% 
  group_by(object) %>% 
  count(use) %>% 
  arrange(desc(n)) %>% 
  print(n=300)
```

## H2: Semantic Similarity

```{r}
iriss_semantic_similarities <- read_csv("data/iriss_semantic_similarities.csv") %>% 
    mutate(condition=case_when(condition=="Passenger"~"Low-Agency",
                             condition=="Pilot"~"High-Agency",
                             condition=="Control"~"Control"))
# iriss_semantic_similarity_mod <- lmer(similarity ~ condition + (1|object) + (1|submitter_id), data=iriss_semantic_similarities)
# summary(iriss_semantic_similarity_mod)
# 
# sjPlot::tab_model(iriss_semantic_similarity_mod)



```

According to the linear mixed model, participants in the low-agency condition produce significantly more similar ideas than the Control group. \### Noncompliance in AI Access conditions

This is JUST on the submission side. Here, we identify the trials on which high-agency participants and low-agency participants did not use AI, regardless of whether ideas from those conversations got evaluated.

```{r}

# Some of these were not evaluated
no_chats_high_agency <- read_csv("data/pilot_no_first_message.csv")

no_chats_low_agency <- read_csv("data/passenger_no_first_message.csv")

noncompliant_conversations <- bind_rows(no_chats_high_agency, no_chats_low_agency) %>% 
  rename(submitter_id = participant_id) %>% 
  mutate(condition=case_when(condition=="Passenger"~"Low-Agency",
                             condition=="Pilot"~"High-Agency",
                             condition=="Control"~"Control"))


# Number of noncompliant conversations
noncompliant_conversations %>% 
  group_by(condition) %>% 
  summarize(n_distinct(submitter_id))
```

## Subsetting of conversations and participants based on which conversations were evaluated and which were compliant

```{r}
# Number of conversations that actually got rated


evaluated_conversations <- iriss_manual_ratings_metrics %>% 
  group_by(submitter_id, condition, object) %>% 
  summarize(aggregated_uses = paste(use, collapse = "; "))


compliant_conversations <- evaluated_conversations %>% 
  anti_join(noncompliant_conversations, by=c("submitter_id", "object"))

# unevaluated_conversations <- iriss_conversations %>% 
#   anti_join(evaluated_conversations, by=c("submitter_id", "condition", "object"))
```

### Evaluated, compliant conversations

After exclusions, there were 123 participants in total

```{r}
# Exclude the noncompliant conversations from the analysis
compliant_conversations %>%
  group_by(condition) %>%
  summarize(unique_people = n_distinct(submitter_id))


write_csv(compliant_conversations, "data/evaluated_compliant_conversations.csv")

compliant_conversations_process <- compliant_conversations %>% 
  left_join(process_vars, by=c("submitter_id", "object")) %>%
  mutate(across(conv_with_ai_1:intrinsic_motivation_4, as.numeric),
         intrinsic_motivation_mean = rowMeans(
      across(intrinsic_motivation_1:intrinsic_motivation_4),
      na.rm = TRUE
    )) %>%
    mutate(
         conv_with_ai_mean = rowMeans(
      across(conv_with_ai_1:conv_with_ai_3),
      na.rm = TRUE
    )) %>%
    mutate(
         consideration_aid_mean = rowMeans(
      across(consideration_aid_1:consideration_aid_3),
      na.rm = TRUE
    ))

# compliant_trials %>% 
#   distinct(condition, submitter_id, object) %>% 
#   filter(condition != "Control") %>% 
#   count(condition)
# 
# compliant_trials %>% 
#   distinct(condition, submitter_id) %>% 
#   count(condition)

# Which participants were completely excluded because all of their trials were noncompliant?


# excluded_participants <- noncompliant %>%
#   count(submitter_id, condition) %>%
#   filter(n==3) %>% 
#   arrange(condition)
# 
# write_csv(excluded_participants, "data/fully_excluded_participants.csv")
# 
# excluded_participants %>% 
#   count(condition)
# 
# # Which participants had AT LEAST ONE noncompliant trial?
# flagged_participants <- noncompliant %>%
#   distinct(submitter_id, condition)


compliant_ideas <- compliant_conversations %>% 
  separate_rows(aggregated_uses, sep = "; ") %>% 
  rename(use="aggregated_uses") %>% 
  distinct(submitter_id, condition, object, use)
```

### Evaluated compliant ideas

```{r}
write_csv(compliant_ideas, "data/evaluated_compliant_ideas.csv")
```

```{r}
compliant_ideas %>% 
  mutate(use = str_to_lower(use)) %>% 
  group_by(condition, object) %>% 
  count(use) %>% 
  arrange(desc(n)) 
```

```{r}
compliant_ideas %>% 
  mutate(use = str_to_lower(use)) %>% 
  group_by(condition) %>% 
  summarise(n_matches = sum(str_detect(use, "\\bart\\b|diy")))


compliant_ideas %>% 
  mutate(use = str_to_lower(use)) %>% 
  filter(str_detect(use, "\\bart\\b|diy")) %>% 
  arrange(condition) %>% 
  print(n=80)
```

## Cluster analysis
```{r}
embeddings <- read_csv("data/evaluated_compliant_ideas_with_embeddings.csv")
```

```{python}
# from sentence_transformers import SentenceTransformer
# import pandas as pd
# import numpy as np
# import os
# os.environ["TOKENIZERS_PARALLELISM"] = "false"
# 
# 
# # Load the sentence transformer model
# model = SentenceTransformer('all-MiniLM-L6-v2')
# 
# # Load the data
# 
# data_path = '~/Git_Projects/idea_generation/data/evaluated_compliant_ideas.csv'  # Update with your actual data path
# df = pd.read_csv(data_path)
# 
# # For each combination of experimental condition, object, and submitter_id, compute the semantic similarity of ideas
# results = []
# for (condition, obj, submitter_id), group in df.groupby(['condition', 'object', 'submitter_id']):
#     ideas = group['use'].tolist()
# 
#     # Compute embeddings
#     embeddings = model.encode(ideas)
# 
#     # Compute cosine similarity matrix
#     norm_embeddings = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)
#     similarity_matrix = np.dot(norm_embeddings, norm_embeddings.T)
# 
#     # Extract upper triangle of the similarity matrix, excluding the diagonal
#     upper_tri_indices = np.triu_indices_from(similarity_matrix, k=1)
#     similarities = similarity_matrix[upper_tri_indices]
# 
#     # Store results
#     for sim in similarities:
#         results.append({
#             'condition': condition,
#             'object': obj,
#             'submitter_id': submitter_id,
#             'similarity': sim
#         })
# 
# # Convert results to DataFrame
# compliant_similarity_df = pd.DataFrame(results)
# summary_output_path = os.path.expanduser('~/Git_Projects/idea_generation/data/compliant_semantic_similarity_summary.csv')
```

## H1 and 2: Compliant analyses

Exclude the trials where participants in the treatment groups did not use AI.


### Age and gender covariates

```{r}
# Add age and gender covariates
demographics_recoded <- submitter_demographics %>% 
  mutate(gender=if_else(gender=="Female",1, 0),
         race=if_else(race=="White or Caucasian",1,0))

# 
# similarity_demographics <- left_join(compliant_similarities, demographics_recoded, by="submitter_id") 



```


```{r}
# One operationalization
compliant_similarities <- read_csv("data/compliant_semantic_similarities.csv")

# Doshi operationalization
iriss_doshi <- read_csv("data/doshi_centroid_analysis.csv") %>% 
  left_join(demographics_recoded,
            by="submitter_id")
  # mutate(race_recoded = 
  #          if_else(race == "3", "White", "Non-White")) %>% 
  # mutate(gender_recoded =
  #          if_else(gender == "2", "Female", "Non-Female"))

iriss_doshi_mod <- lmer(similarity_to_cond_obj ~ 
                          condition + 
                          scale(age) +
                          as.factor(race) +
                          as.factor(gender) +
                          (1|object) + 
                          (1|submitter_id), 
                        data=iriss_doshi)
summary(iriss_doshi_mod)
anova(iriss_doshi_mod, type = 3)

iriss_doshi %>% 
  group_by(condition) %>% 
  get_summary_stats(sim_cond_ideas, 
                    type="mean_sd") %>% 
  arrange(desc(mean))

cond_means <- emmeans(iriss_doshi_mod, "condition")
posthoc_results <- pairs(cond_means, adjust="tukey")
print(posthoc_results)

```


## Doshi Operationalization
```{r}
doshi_plot <- iriss_doshi %>% 
  mutate(condition = fct_relevel(condition,
                                 "Low-Agency",
                                 "High-Agency",
                                 "Control")) %>% 
  ggplot(aes(x = condition, y = similarity_to_cond_obj, fill = condition)) +
  # Add the 'Cloud' (Density half-violin)
  stat_halfeye(
    adjust = .5, 
    width = .6, 
    .width = 0, 
    justification = -.3, 
    point_colour = NA
  ) +
  # Add the 'Rain' (Raw data points)
  # geom_dots(
  #   side = "left", 
  #   dotsize = .4, 
  #   justification = 1.1, 
  #   binwidth = .005,
  #   alpha = 0.5
  # ) +
  # Add a small Boxplot to show the median and quartiles
  geom_boxplot(
    width = .15, 
    outlier.shape = NA, # Outliers are already visible in the 'rain'
    alpha = 0.5
  ) +
  stat_summary(fun="mean") +
  # Aesthetics and Labels
  scale_fill_manual(values = c(
    "Control" = "#2c3e50",
    "Low-Agency" = "#e31a1c",
    "High-Agency" = "#18bc9c"
  )) +
  scale_y_continuous(
    breaks = seq(0, 1, by = 0.1)
  ) +
  coord_cartesian(clip="on") +
  theme_apa() +
  labs(
    x = "Condition",
    y = "Homogeneity (Similarity to Condition-Object Centroid)",
    fill = "Condition"
  ) +
  coord_flip() + # Flipping makes it easier to read the condition names
  theme(legend.position = "none")
doshi_plot
ggsave("figures/doshi_homogeneity.png", doshi_plot)
```

### Top-performing ideas by condition

```{r}
iriss_manual_ratings_metrics %>% 
  semi_join(compliant_ideas, by=c("submitter_id", "object")) %>% 
  group_by(condition) %>% 
  arrange(    
    desc(creativity)) %>% 
  dplyr::select(object, submitter_id, condition, use, creativity, originality, usefulness) %>% 
  print(n=100) %>% 
  kbl()


```

### Table of ideas

```{r}
iriss_manual_ratings_metrics %>% 
  semi_join(compliant_ideas, by = c("submitter_id", "object")) %>% 
  filter(object == "brick",
         condition=="High-Agency") %>% 
  group_by(condition) %>% 
  arrange(desc(condition),
          desc(creativity)) %>% 
  distinct(condition, use, creativity, originality, usefulness) %>% 
  ungroup() %>% 
  gt(rowname_col = "condition") %>%  # optional: make 'use' the row label
  tab_header(
    title = "Evaluations of Individual Ideas"
  ) %>% 
  fmt_number(
    columns = vars(creativity, originality, usefulness),
    decimals = 2
  ) %>% 
  tab_style(
    style = list(
      cell_text(weight = "bold", color = "white"),
      cell_fill(color = "#4B4B4B")
    ),
    locations = cells_column_labels(
      columns = everything()
    )
  ) %>% 
  opt_table_font(stack = "geometric-humanist") 
```

```{r}
evaluations <- iriss_manual_ratings_metrics %>% 
  semi_join(compliant_ideas, by=c("submitter_id", "object", "use"))
```

### Linear mixed model with compliant data

```{r}
compliant_trials_demographics <- left_join(evaluations, demographics_recoded, by="submitter_id")
```

# Descriptives

```{r}
compliant_trials_demographics %>% 
  group_by(condition) %>% 
  get_summary_stats(c(creativity, originality, usefulness), type="mean_sd") %>% 
  pivot_wider(names_from = "variable", values_from = c("mean", "sd")) %>% 
  mutate(
    creativity = paste0(round(mean_creativity, 2), " (", round(sd_creativity, 2), ")"),
    originality = paste0(round(mean_originality, 2), " (", round(sd_originality, 2), ")"),
    usefulness = paste0(round(mean_usefulness, 2), " (", round(sd_usefulness, 2), ")")
  ) %>% 
  select(condition, creativity, originality, usefulness) %>% 
  gt() %>% 
  opt_table_font(stack = "geometric-humanist") %>% 
    cols_label(
    condition = "Condition",
    creativity = "Creativity",
    originality = "Originality",
    usefulness = "Usefulness"
  ) %>%
  tab_style(
    style = list(
      cell_text(weight = "bold")
    ),
    locations = cells_column_labels(everything())
  )
```

### Most creative submitters

```{r}
submitter_creativity <- compliant_trials_demographics %>% 
  group_by(submitter_id, condition) %>% 
  summarize(creativity = mean(creativity)) %>% 
  arrange(desc(creativity))

ggplot(submitter_creativity, (aes(x=creativity, fill=condition))) +
  geom_dotplot(stackgroups = TRUE, method="histodot", dotsize=1.25) +
  facet_wrap(~condition) +
  theme_apa() +
  scale_x_continuous(breaks = seq(1, 5, by = 1)) +
  labs(x="Participant's overall creativity",
       y="Proportion of sample") +
  scale_fill_manual(values = c("Control" = "#619bff", "High-Agency" = "#00BA38", "Low-Agency" = "#F8766D")) +
  theme(legend.position="none")
```

```{r}
compliant_trials_demographics %>% 
  group_by(condition) %>% 
  get_summary_stats(usefulness, type="mean_sd")

compliant_originality_mod <- lmer(
  originality ~ 
    scale(age) + 
    as.factor(gender) + 
    as.factor(race) + 
    condition +
    (1|object) + 
    (1|submitter_id), data=compliant_trials_demographics)
summary(compliant_originality_mod)

compliant_creativity_mod <- lmer(
  creativity ~ 
    scale(age) + 
    as.factor(gender) + 
    as.factor(race) + 
    condition +
    (1|object) + 
    (1|submitter_id), data=compliant_trials_demographics)
summary(compliant_creativity_mod)

compliant_usefulness_mod <- lmer(
  usefulness ~ 
    scale(age) + 
    as.factor(gender) + 
    as.factor(race) + 
    condition +
    (1|object) + 
    (1|submitter_id), data= compliant_trials_demographics
)
summary(compliant_usefulness_mod)
anova(compliant_usefulness_mod, type=3)
effectsize::eta_squared(compliant_usefulness_mod)
emmeans(compliant_usefulness_mod, pairwise ~ condition)

# 
# sjPlot::tab_model(compliant_creativity_mod, compliant_originality_mod, compliant_usefulness_mod,
#                   pred.labels = c("Intercept",
#                                   "High-Agency Condition",
#                                   "Low-Agency Condition",
#                                   "Age",
#                                   "Gender (Female)",
#                                   "Race (White)"),
#                   string.ci = "95% CI",
#                   dv.labels = c("Creativity", "Originality", "Usefulness"))

summary(compliant_originality_mod)   
anova(compliant_originality_mod)

class(compliant_creativity_mod) <- "lmerMod"
class(compliant_originality_mod) <- "lmerMod"
class(compliant_usefulness_mod) <- "lmerMod"
stargazer(compliant_creativity_mod, compliant_originality_mod, compliant_usefulness_mod, type = "latex", out = "tables/individual_metrics.tex")
```

```{r}
homogeneity_demographics <- left_join(compliant_similarities, demographics_recoded, by="submitter_id")

nomic_similarities <- read_csv("data/nomic_similarities.csv")

nomic_demographics <- left_join(nomic_similarities, demographics_recoded, by="submitter_id")
```

# H2 with Compliant Ideas
```{r}
compliant_semantic_similarity_mod <- lmer(similarity ~ condition + (1|object) + (1|submitter_id), data=homogeneity_demographics)
anova(compliant_semantic_similarity_mod)
effectsize::eta_squared(compliant_semantic_similarity_mod)


compliant_similarity_demographics_mod <- lmer(
  similarity ~ 
    scale(age) + 
    as.factor(gender) + 
    as.factor(race) +
    condition + 
    (1|object) + 
    (1|submitter_id), 
  data=homogeneity_demographics)
summary(compliant_similarity_demographics_mod)

nomic_mod <- lmer(
  similarity ~
    scale(age) + 
    as.factor(gender) + 
    as.factor(race) +
    condition + 
    (1|submitter_id), 
  data=nomic_demographics
)
summary(nomic_mod)


# sjPlot::tab_model(compliant_similarity_demographics_mod,
#                   pred.labels = c("Intercept",
#                                   "High-Agency Condition",
#                                   "Low-Agency Condition",
#                                   "Age",
#                                   "Gender (Female)",
#                                   "Race (White)"),
#                   string.ci = "95% CI",
#                   dv.labels = "Homogeneity")
class(compliant_similarity_demographics_mod) <- "lmerMod"
class(iriss_doshi_mod) <- "lmerMod"
stargazer(compliant_similarity_demographics_mod, iriss_doshi_mod, type="latex", out = "tables/homogeneity.tex")
```

```{r}
centroid <- read_csv("data/centroids.csv")

centroid_demographics <- centroid %>% 
 left_join(demographics_recoded, by="submitter_id")

ggplot(centroid, aes(x = condition,
                     y = semantic_distance)) +
  geom_boxplot() +
  stat_summary(fun="mean") 

centroid_mod <- lmer(
  semantic_distance ~
    scale(age) + 
    as.factor(gender) + 
    as.factor(race) +
    condition + 
    (1|submitter_id), 
  data=centroid_demographics
)
summary(centroid_mod)

```


```{r}
similarity_stats <- aov(similarity ~ condition, data=compliant_similarities)
anova(compliant_semantic_similarity_mod)
# F_to_eta2(4.45, df=2, df_error=120.12)
effectsize::eta_squared(compliant_semantic_similarity_mod)

# Get estimated marginal means
emm <- emmeans(compliant_semantic_similarity_mod, ~ condition, lmerTest.limit=3380)

# With adjustment for multiple comparisons (Tukey is default)
pairs(emm, adjust = "tukey", reverse = TRUE)


```

## Compliant Originality Plot

```{r}

outcomes <- c("originality", "creativity", "usefulness")

plots <- map(outcomes, function(var) {
  summary_df <- compliant_trials_demographics %>%
    mutate(condition= fct_relevel(condition, c("Low-Agency", "High-Agency", "Control"))) %>% 
    group_by(submitter_id, condition) %>%
    summarize(value = mean(.data[[var]]), .groups = "drop")
  
  ggplot(summary_df, aes(x = value, y = condition, fill = condition)) +
    geom_density_ridges(alpha = 0.6, 
                        quantile_lines = TRUE, 
                        quantile_fun = mean) +
    xlim(c(1,5)) +
    labs(x = str_to_title(var), y = "") +
    theme_apa() +
    theme(legend.position = "none")
})

# To display the plots:
originality <- plots[[1]]  # originality
creativity <- plots[[2]]  # creativity
usefulness <- plots[[3]]  # usefulness

ggsave("figures/originality.png", plot = plots[[1]])
ggsave("figures/creativity.png", plot = plots[[2]])
ggsave("figures/usefulness.png", plot = plots[[3]])


# Combined plot
compliant_evaluation_plot <- creativity + originality + usefulness + plot_annotation(tag_levels = "a")
compliant_evaluation_plot

ggsave(plot=compliant_evaluation_plot, filename="figures/compliant_evaluations.png",
  width = 10,  # Wide
  height = 4)
```
```{r}

outcomes <- c("originality", "creativity", "usefulness")

plots <- map(outcomes, function(var) {
  # Aggregate to the participant level first as in your original code
  summary_df <- compliant_trials_demographics %>%
    mutate(condition = fct_relevel(condition, c("Low-Agency", "High-Agency", "Control"))) %>% 
    group_by(submitter_id, condition) %>%
    summarize(value = mean(.data[[var]], na.rm = TRUE), .groups = "drop")
  
  ggplot(summary_df, aes(x = condition, 
                         y = value, 
                         color = condition)) +
    # stat_summary handles the bootstrapping automatically
    geom_point(position = 
                 position_jitter(width = 0.2, height = 0),
               alpha = .4) +
    stat_summary(aes(fill=condition),
                 fun.data = mean_cl_boot,
                 geom = "pointrange",
                 shape = 21,
                 color = "black") +
    scale_x_discrete(labels = c("Low-Agency" = "Low-\nAgency", 
                                "High-Agency" = "High-\nAgency", 
                                "Control" = "Control")) +
    scale_y_continuous(limits = c(1, 5)) +
    labs(y = str_to_title(var), x = "") +
    theme_apa() +
    theme(legend.position = "none")
})

# Access individual plots
originality <- plots[[1]]
creativity <- plots[[2]]
usefulness <- plots[[3]]

# Combine plots
compliant_evaluation_plot <- creativity + originality + usefulness + 
  plot_annotation(tag_levels = "a")

# Display and Save
print(compliant_evaluation_plot)

ggsave("figures/compliant_evaluations.png",
       plot = compliant_evaluation_plot,
       width = 10,
       height = 4)
```

## Compliant Similarity Plot

```{r}

similarity_means_df <- compliant_similarities %>%
  group_by(condition) %>%
  summarise(mean_similarity = mean(similarity, na.rm = TRUE))

compliant_semantic_similarity_plot <- compliant_similarities %>% 
  mutate(condition= fct_relevel(condition, c("Low-Agency", "High-Agency", "Control"))) %>% 
  ggplot(aes(x=similarity, y=condition, fill=condition)) +
  geom_density_ridges(alpha=.6,
                      quantile_lines = TRUE,
                      quantile_fun = mean) +
  geom_text(
    data = similarity_means_df,
    aes(x = mean_similarity, y = condition, 
        label = round(mean_similarity, 2)),   # label = numeric mean
    nudge_x = -0.05,    # shift to the right of the mean line
    nudge_y = 0.8,  
    size = 3.5,
    color = "black"
  ) +
  scale_x_continuous(breaks=seq(-.5, 1, by=.1)) +
  labs(x="Homogeneity",
       y="") +
  theme_apa() +
  theme(legend.position = "none") 

compliant_semantic_similarity_plot

ggsave("figures/compliant_semantic_similarity.png", plot=compliant_semantic_similarity_plot)
```

```{r}
compliant_raincloud_plot <- compliant_similarities %>%
  mutate(condition=fct_relevel(condition,
                               "Low-Agency",
                               "High-Agency",
                               "Control")) %>% 
  ggplot(aes(y = condition, 
             x = similarity, 
             fill = condition)) +
  
  # 1. The Cloud (Density)
  # justification = 0 and position_nudge(y = 0.2) keeps it strictly ABOVE the center line
  stat_halfeye(
    adjust = .5, 
    width = .3,      # Limits how 'tall' the density can get
    .width = 0, 
    justification = 0, 
    point_colour = NA,
    position = position_nudge(y = 0.15),
    alpha = .8
  ) +
  geom_point(
    aes(color=condition),
    alpha = .6,
    position = position_jitter(width = .005),
    size=1
  ) +
  
  # 3. The Boxplot (The "Horizon")
  # width = 0.1 keeps it very thin right on the condition's axis line
  geom_boxplot(
    width = 0.1,
    outlier.shape = NA,
    alpha = 0.3
  ) +
  
  # 4. Remove Whitespace & Bleeding
  # expand = c(0, 0) removes the default 5% padding around the categories
  scale_y_discrete(expand = c(0, 0.5)) + 
  
  scale_x_continuous(breaks = seq(-.5, 1, by = .1)) +
  scale_color_manual(values = c(
    "Control" = "#2c3e50",
    "Low-Agency" = "#e31a1c",
    "High-Agency" = "#18bc9c"
  )) +
  scale_fill_manual(values = c(
    "Control" = "#2c3e50",
    "Low-Agency" = "#e31a1c",
    "High-Agency" = "#18bc9c"
  )) +
  
  # Crop the plot area to remove the empty space at the very bottom
  coord_cartesian(clip = "on") + 
  
  labs(x = "Homogeneity (Similarity to One's Own Ideas)", y = "") +
  theme_apa() +
  theme(
    legend.position = "none",
    # This adjusts the physical spacing between the condition rows
    panel.spacing = unit(0, "lines") 
  )

compliant_raincloud_plot
```


```{r}
ggsave("figures/raincloud.png", compliant_raincloud_plot)
```

Around 24% of the low-agency conversations did not use AI and around 38% of the high-agency conversations did not use AI. Excluding the noncompliant trials did not change the results.

```{r}
similarities_means_plot <- compliant_similarities %>% 
  mutate(condition= fct_relevel(condition, c("Low-Agency", "High-Agency", "Control"))) %>% 
  group_by(condition) %>% 
  get_summary_stats(similarity, type="mean_se") %>% 
  ggplot(aes(x=condition, y=mean, color=condition)) +
  geom_point() +
  geom_errorbar(aes(ymin = mean-se, ymax = mean+se))+
  ylim(c(0,1))

similarities_means_plot
```

```{r}
# Table of descriptives
similarities_descriptives <- compliant_similarities %>% 
  group_by(condition) %>% 
  get_summary_stats(similarity, type="mean_sd") %>% 
  select(-c(variable, n)) %>% 
  gt() %>% 
  fmt_number(
    columns = c(mean, sd),
    decimals = 2
  ) %>% 
  cols_label(
    condition = "Condition",
    mean = "Mean",
    sd = "SD"
  ) %>% 
  tab_header(
    title = "Homogeneity by Condition"
  ) %>% 
  tab_options(
    table.border.top.color = "white",
    table.border.bottom.color = "white"
  ) %>% 
  opt_table_font(stack = "geometric-humanist") %>% 
  tab_style(
  style = list(
    cell_text(weight = "bold")
  ),
  locations = cells_column_labels()
) %>% 
  tab_source_note(
    source_note = "Note: Higher values indicate greater homogeneity."
  )

similarities_descriptives





```

Who were the highest-performing participants?

```{r}
evaluations %>% 
  group_by(submitter_id) %>% 
  summarize(mean_creativity = mean(creativity)) %>% 
  arrange(desc(mean_creativity))


most_creative_participants <- iriss_manual_ratings_metrics %>% 
  filter(submitter_id %in% c("R_626PnHWHD8OebPr",
                             "R_665Usq3Hx2qiS2y",
                             "R_1C4pbfUTsEaLjCV",
                             "R_5ebqE9oR2LkKvO9",
                             "R_7wcOe7LsUrh7hzH",
                             "R_5z92Djt5TP9CJBb",
                             "R_7nZ3ULt8wE34mW6",
                             "R_6dB0PTZKZgdwBAS"))
  
```

```{r}
# Factor analysis of intrinsic motivation items

intrinsic_motivation <- ' f =~ intrinsic_motivation_1 + intrinsic_motivation_2 + intrinsic_motivation_3 + intrinsic_motivation_4' 

onefac4items <- cfa(intrinsic_motivation, data=compliant_conversations_process)
summary(onefac4items, fit.measures=TRUE, standardized=TRUE)
```

CFI indicates good fit (.92)

### Intrinsic motivation during task

```{r}
# # make a composite intrinsic motivation item
# evaluations <- evaluations %>% 
#   group_by(submitter_id) %>% 
#   mutate(intrinsic_motivation, type="mean_sd")
# 
# # Plot intrinsic motivation
# intrinsic_motivation_p <- evaluations %>% 
#   distinct(submitter_id, condition, intrinsic_motivation_mean) %>%
#   ggplot(aes(x=intrinsic_motivation_mean, y=fct_relevel(condition, "low-agency", "high-agency", "Control"), fill=condition)) +
#   geom_density_ridges(
#     quantile_lines=TRUE, 
#     quantile_fun=mean) +
#   scale_fill_manual(
#     values = c(
#       "Control" = "#619CFF",
#       "low-agency" = "#F8766D",
#       "high-agency" = "#00BA38"
#     )) +
#   labs(x="Intrinsic motivation",
#        y="Condition") +
#   scale_x_continuous(breaks=seq(1, 7, by=1)) +
#   coord_cartesian(xlim = c(1,7)) +
#   theme_apa() +
#   theme(legend.position="none")
# 
# ggsave("figures/intrinsic_motivation.png", plot=intrinsic_motivation_p)
```

```{r}
# # Statistical test
# 
# compliant_submitters <- evaluations %>% 
#   distinct(submitter_id, condition, conv_with_ai_mean, consideration_aid_mean, intrinsic_motivation_mean)
# 
# intrinsic_motivation_model <- stats::aov(intrinsic_motivation_mean ~ condition, data=compliant_submitters)
# summary(intrinsic_motivation_model)
# 
# emmeans(intrinsic_motivation_model, pairwise ~ condition, adjust = "bonferroni")
# # Comparing participants in the high- and low-agency conditions on intrinsic motivation, consideration AI, and conversation with AI
# 
# 
# 
# t.test(compliant_submitters$conv_with_ai_mean[compliant_submitters$condition == "high-agency"],
#        compliant_submitters$conv_with_ai_mean[compliant_submitters$condition == "low-agency"])
# 
# t.test(compliant_submitters$consideration_aid_mean[compliant_submitters$condition == "high-agency"],
#        compliant_submitters$consideration_aid_mean[compliant_submitters$condition == "low-agency"])
```

```{r}
# Does the difference in self-perceived vs. other-perceived creativity vary by condition?

# perception_diffs <- self_other_perceptions %>% 
#   mutate(creativity_diff = self_creativity-creativity,
#          originality_diff = self_originality-originality,
#          usefulness_diff = self_usefulness-usefulness)
# 
# 
# perception_diffs %>% 
#   group_by(condition) %>% 
#   get_summary_stats(c(creativity_diff, originality_diff, usefulness_diff), type ="mean_sd") %>% 
#   ggplot(aes(x=condition,y=mean)) +
#   geom_point() +
#   facet_wrap(~variable)
# 
# perception_summary <- perception_diffs %>% 
#   group_by(condition) %>% 
#   get_summary_stats(c(creativity_diff, originality_diff, usefulness_diff), 
#                     type = "mean_sd") %>% 
#   mutate(sem = sd / sqrt(n))  # calculate SEM
# 
# perception_summary %>% 
#   ggplot(aes(x = condition, y = mean)) +
#   geom_point() +
#   geom_errorbar(aes(ymin = mean - sem, ymax = mean + sem), width = 0.1) +
#   facet_wrap(~variable) +
#   ylab("Mean Â± SEM")
# 
# # Statistical analysis
# 
# perception_diff_participants <- perception_diffs %>% 
#   group_by(submitter_id, condition) %>% 
#   summarize(creativity_diff = mean(creativity_diff),
#             originality_diff = mean(originality_diff),
#             usefulness_diff = mean(usefulness_diff))
# 
# creativity_diff_anova <- aov(creativity_diff ~ condition,
#   data = perception_diff_participants
# )
# summary(creativity_diff_anova)
# 
# originality_diff_anova <- aov(originality_diff ~ condition, data=perception_diff_participants)
# summary(originality_diff_anova)
# 
# usefulness_diff_anova <- aov(usefulness_diff ~ condition, data=perception_diff_participants)
# summary(usefulness_diff_anova)

# # Predict difference score from condition, submitter ID, and object
# lmer(creativity_diff ~ condition + (1|submitter_id) + (1|object), data=perception_diffs) 
```

### Timing

```{r}
duration <- iriss %>% 
  select(submitter_id, condition, contains("Duration")) %>% 
  mutate(across(c(3:6), as.numeric)) %>% 
  rename(duration_sec = "Duration (in seconds)") %>% 
  mutate(duration_min = duration_sec/60) %>% 
  relocate(duration_min, .after=duration_sec)

duration %>% 
  get_summary_stats(duration_min, type = "five_number")


# Timing variables refer to the amount of time it took the participant to read their condition's instructions
timing <- iriss %>% 
  select(submitter_id, condition, contains("Page Submit")) %>% 
  mutate(across(c(3:5), as.numeric)) %>% # Make all timer columns numeric
  pivot_longer(cols=starts_with("timer"), names_to = "trial", values_to = "duration") 
```

```{r}
# Perceptions of uniqueness in the evaluated, compliant sample
uniqueness <- iriss_self_perceptions %>% 
  right_join(compliant_conversations, by=c("submitter_id", "object")) %>% 
  mutate(unique=as.numeric(unique))

unique_lm <- lm(unique~condition.x, data=uniqueness)
summary(unique_lm)
```

```{r}
intent <- read_csv("data/iriss_intent_classification.csv") %>% 
  rename(submitter_id="participant_id") 

intent %>% 
  group_by(condition) %>% 
  summarize(mean_doing = mean(doing),
            sd_doing = sd(doing))


```

### Direct Asks

```{r}
direct_asks <- read_csv("data/direct_asks.csv") %>% 
  rename(submitter_id = "ResponseId") %>% 
  mutate(Condition=case_when(Condition=="passenger"~"Low-Agency",
                             Condition=="pilot"~"High-Agency")) %>% 
  rename(condition="Condition")

# Direct ask plot
direct_asks_p <- direct_asks %>% 
  mutate(condition = case_when(
    condition == "High-Agency" ~ "High-Agency<br><i>N</i> = 36",
    condition == "Low-Agency"  ~ "Low-Agency<br><i>N</i> = 40",
    TRUE ~ condition
  )) %>% 
  group_by(condition) %>% 
  get_summary_stats(direct_ask_proportion, type="mean_se") %>% 
  ggplot(aes(x=condition, y=mean, color=condition)) +
  geom_point(size=4) +
  geom_errorbar(aes(ymin=mean-se, ymax=mean+se), width=0) +
  scale_color_manual(
    values = c(
      "Low-Agency<br><i>N</i> = 40" = "#F8766D",
      "High-Agency<br><i>N</i> = 36" = "#00BA38"
    )) +
  ggsignif::geom_signif(
    comparisons = list(c("High-Agency<br><i>N</i> = 36", "Low-Agency<br><i>N</i> = 40")), 
    annotations = "***",
    y_position = 0.95,
    tip_length = 0.01,
    textsize = 6,
    color="black"
  ) +
  ylim(c(0,1)) +
  labs(x="",
       y="Proportion of direct asks") +
  theme_apa() +
  theme(legend.position="none",
        axis.text.x = element_markdown())

direct_asks_p

ggsave("figures/
       direct_asks.png", plot=direct_asks_p)


t.test(data=direct_asks, direct_ask_proportion~condition, var.equal = TRUE)
```

```{r}
# Does the proportion of direct asks correlate with person-level homogeneity?

participant_compliant_similarity <- compliant_similarities %>%
  # filter(condition %in% c("Low-Agency", "High-Agency")) %>% 
  group_by(submitter_id, condition) %>% 
  summarize(mean_similarity = mean(similarity))

direct_ask_similarity <- full_join(direct_asks, participant_compliant_similarity, by=c("submitter_id", "condition")) %>% 
    mutate(direct_ask_binary = if_else(direct_ask_proportion==0, 0, 1)) # If no direct asks, they get coded as Guided Ideation

ggplot(direct_ask_similarity, aes(x=direct_ask_proportion,y=mean_similarity)) +
  geom_point() +
  stat_smooth()

cor.test(direct_ask_similarity$direct_ask_proportion, direct_ask_similarity$mean_similarity, method="spearman")

direct_ask_sim_model <- lm(mean_similarity ~ direct_ask_proportion*condition, data = direct_ask_similarity)
summary(direct_ask_sim_model)


ggplot(direct_ask_similarity, aes(x=direct_ask_binary, y=mean_similarity)) +
  geom_point() 

# Logistic regression predicting direct ask from condition
direct_ask.log <- glm(direct_ask_binary ~ condition, family = "binomial", data=direct_ask_similarity)
summary(direct_ask.log)
exp(coef(direct_ask.log))

# Does direct ask binary predict mean similarity?

direct_ask.lm <- lm(mean_similarity ~ direct_ask_binary*condition, data=direct_ask_similarity)
summary(direct_ask.lm)
```

# Relationship between individual-level creativity and homogeneity

```{r}
creativity_homogeneity <- full_join(participant_compliant_similarity, submitter_creativity)

ggplot(creativity_homogeneity, aes(x=creativity, y=mean_similarity, color=condition)) +
  geom_point() +
  geom_smooth(method="lm") +
  labs(x="Participant's overall creativity",
       y="Participant's overall homogeneity") +
  scale_color_manual(values = c("Control" = "#619bff", "High-Agency" = "#00BA38", "Low-Agency" = "#F8766D")) 
```

## Post-hoc power analysis

```{r, echo=FALSE}
sim_treatment <- powerSim(compliant_semantic_similarity_mod, nsim=100)
sim_treatment

#extending number of people
fit_similarity_mod_people <- simr::extend(compliant_semantic_similarity_mod, within = "submitter_id+condition", n=200)
fit_similarity_mod_people
anova(fit_similarity_mod_people)

#running power curve
powerCurve_people <- simr::powerCurve(fit_similarity_mod_people,
                                       simr::fixed("condition"),
                                       within = "submitter_id+condition",
                                       nsim=100, alpha=.05, progress=TRUE)

summary(powerCurve_people)
plot(powerCurve_people)

```

```{r}
set.seed(123)  # for reproducibility

# Choose 50 participants randomly
pilot_sub <- compliant_similarities[sample(nrow(compliant_similarities), 50), ]
model_sub <- lmer(similarity ~ condition + (1 | object) + (1 | submitter_id), data = pilot_sub)
summary(model_sub)

# Set differences in betas relative to control group
fixef(model_sub)["conditionLow-Agency"]  <- 0.100

# If you plan to run the full study with more participants:
model_extended <- extend(model_sub, along="submitter_id", n=200)

# Check power for Low vs Control
power_result <- powerSim(model_extended) 
power_result

```

# Stanford Sample

```{r}
stanford_sample <- read_csv("data/stanford_sample.csv") %>% 
  filter(Finished=="1") %>% 
  rename("condition" = FL_3_DO) %>% 
  drop_na(condition)

lost_data <- stanford_sample %>% 
  filter(str_detect(q1_chatConversationLog, pattern="OpenAI billing"))

stanford_wrangled <- stanford_sample %>% 
  relocate(condition, .after = attn_check_4_TEXT) %>% 
  anti_join(lost_data, by="ResponseId") %>% 
  mutate(condition = case_when(condition == "GuidedInstructions" ~ "high-agency",
                               condition == "UnguidedInstructions" ~ "low-agency",
                               condition == "ControlInstructions" ~ "Control")) %>% 
  filter(Progress=="100") %>% 
  rename(submitter_id = "ResponseId") %>% 
  mutate(age = as.numeric(age))
```
```{r}
stanford_demographics <- stanford_wrangled %>%
  mutate(gender = case_when(gender == "1" ~ "Male",
                            gender == "2" ~ "Female",
                            gender == "3" ~ "Non-binary",
                            gender == "4" ~ "Prefer to self-describe")) %>% 
  mutate(race = case_when(race == "1" ~ "Black or African-American",
                          race == "2" ~ "American Indian or Alaskan Native",
                          race == "3" ~ "White or Caucasian",
                          race == "4" ~ "Native Hawaiian",
                          race == "5" ~ "Hispanic, Latino or Spanish Origin",
                          race == "6" ~ "Asian-American",
                          race == "7" ~ "Multiracial or self-described")) %>% 
  mutate(race = fct_infreq(race)) %>% 
  dplyr::select(submitter_id, age, gender, race) 

stanford_demographics %>% 
  tbl_summary(include = c(age, gender, race),
              statistic = list(
                all_continuous() ~ "{mean} ({sd})",
                all_categorical() ~ "{n} / {N} ({p}%)"),
              digits = all_continuous() ~ 1,
              label = list(age = "Age",
                           gender = "Gender",
                           race = "Race")) %>% 
   modify_header(label ~ "**Demographic**")
```
```{r}
stanford_trial_data <- stanford_wrangled %>% 
  pivot_longer(names_to = "trial",
                values_to = "use",
                cols = starts_with(c("pilot", "pass", "control"))) %>% 
  mutate(trial = str_remove(trial, "open_")) %>% # fixed naming problem
  filter(grepl("^(pilot|pass|control)_(brick|frisbee|bubble)_[1-5]$", trial)) %>% 
  filter(!is.na(use)) %>% # Keep only the trials with responses
  relocate(trial, .after = "condition") %>% 
  relocate(use, .after = "trial") %>% 
  mutate(object = str_extract(trial, "(?<=_).*")) %>% 
  mutate(object = str_remove(object, "_.*")) %>% 
  relocate(object, .after = "trial") %>% 
  mutate(object = if_else(object == "bubble", "bubblewrap", object))

write_csv(stanford_trial_data, "data/stanford_trial_data.csv")
```

# Bind rows with IRiSS
```{r}
merged_samples <- bind_rows(evaluated_compliant_ideas, stanford_trial_data) %>% 
  mutate(condition = str_to_lower(condition))

write_csv(merged_samples, "data/merged_samples.csv")

# merged_samples_compliant <- merged_samples %>% 
#   filter(q1_chatConversationLog != "NO_CHAT_DATA") 

merged_doshi <- read_csv("data/merged_sample_doshi.csv") 

merged_doshi %>% 
  group_by(condition) %>% 
  get_summary_stats(sim_condition, type="mean_sd")


```

```{r}

# 
# # ---------------------------------------------------------
# # 1. Ensure condition has ALL FOUR LEVELS
# # ---------------------------------------------------------
# compliant_similarities$condition <- factor(
#   compliant_similarities$condition,
#   levels = c("Control", "Low-Agency", "High-Agency", "No-Agency")  # <--- edit if needed
# )
# # ---------------------------------------------------------
# # 2. Draw a random sample AND add sufficient dummy rows
# # ---------------------------------------------------------
# pilot_sub <- compliant_similarities[sample(nrow(compliant_similarities), 50), ]
# 
# # Create MULTIPLE dummy rows for No-Agency (need enough for model to fit)
# # Aim for similar representation as other conditions
# n_dummy <- round(50 / 3)  # distribute evenly across 4 conditions
# 
# dummy_rows <- pilot_sub[1:n_dummy, ]  # copy structure
# dummy_rows$condition <- "No-Agency"
# # Use mean of pilot data as placeholder
# dummy_rows$similarity <- mean(pilot_sub$similarity, na.rm = TRUE)
# 
# # Add to pilot dataset
# pilot_sub2 <- rbind(pilot_sub, dummy_rows)
# 
# # ---------------------------------------------------------
# # 3. Fit mixed model on pilot data
# # ---------------------------------------------------------
# model_sub <- lmer(
#   similarity ~ condition + (1 | object) + (1 | submitter_id),
#   data = pilot_sub2
# )
# 
# summary(model_sub)
# 
# # ---------------------------------------------------------
# # 4. Set hypothetical effect sizes relative to Control
# # ---------------------------------------------------------
# fixef(model_sub)[2] <- 0.10  # Low-Agency
# fixef(model_sub)[3] <- 0.05  # High-Agency
# fixef(model_sub)[4] <- 0.10  # No-Agency
# 
# fixef(model_sub)   # check
# 
# # ---------------------------------------------------------
# # 5. Extend the model to desired N (e.g., 200 participants)
# # ---------------------------------------------------------
# model_extended <- extend(model_sub, along = "submitter_id", n=280)
# 
# # ---------------------------------------------------------
# # 6. Power for each contrast
# # ---------------------------------------------------------
# 
# # ---------------------------------------------------------
# # 6. Power for predictor "condition"
# power <- powerSim(model_extended)
# power
# 
# # ---------------------------------------------------------
# # 7. Optional: run power curves to determine required N
# # ---------------------------------------------------------
# 
# 
# pc <- powerCurve(
#   model_extended,
# )
# pc
# plot(pc)

```
